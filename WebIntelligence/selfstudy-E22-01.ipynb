{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self study 1\n",
    "\n",
    "Self studies should be solved individually, or in small groups of 2-3 students. There is no hand-in of your solutins to the self studies. However, you can bring your solutions to the exam, and use them as the basis for your answers to the exam questions.\n",
    "\n",
    "In this self-study we construct a simple crawler. Concretely, you should: \n",
    "\n",
    "* Select about 5 seed urls, e.g. homepages of universities, e-commerce sites, or similar\n",
    "\n",
    "* Start crawling from these seeds. Define a strategy for selecting the next url to be crawled. What kind of prioritization (if any) is embodied in your strategy?\n",
    "\n",
    "* Make sure you obey the robots.txt file, and make ensure that at least 2 seconds elapse between requests to the same host\n",
    "\n",
    "* Stop when you have crawled approx. 1000 pages\n",
    "\n",
    "* For each crawled page, save the url and the text string contained in the 'title' element of the document (we do not want to handle the full text of the pages at this point).\n",
    "\n",
    "* You can repeat this several times, using different seed sets and/or prioritization strategies.\n",
    "\n",
    "The following two self studies will extend the work that you do in this self study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following introduces a few helpful libraries and essential functions. You can use these methods, or use other tools that you are already familiar with and/or prefer to work with. \n",
    "\n",
    "A simple crawler implementation can be based on the 'requests' package [https://requests.readthedocs.io/en/master/](https://requests.readthedocs.io/en/master/) for retrieving html documents, and the BeautifulSoup parser https://www.crummy.com/software/BeautifulSoup/bs4/doc/ for parsing the html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "from urllib.robotparser import RobotFileParser\n",
    "from urllib.parse import urlparse\n",
    "from datetime import datetime, timedelta\n",
    "from itertools import count\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start crawling at https://www.aau.dk/ . We first retrieve the robots.txt file and check whether we are allowed to crawl the top-level url:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "rp=RobotFileParser()\n",
    "rp.set_url(\"https://www.aau.dk\")\n",
    "rp.read()\n",
    "print(rp.can_fetch(\"*\",\"https://www.aau.dk\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get the html using the requests package, which returns a response object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=requests.get('https://www.aau.dk/')\n",
    "print(type(r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic view of the contents is accessible via the content attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For serious parsing, we can use the BeautifulSoup html parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\johan\\Documents\\Git\\P6Opgaver\\WebIntelligence\\selfstudy-E22-01.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/johan/Documents/Git/P6Opgaver/WebIntelligence/selfstudy-E22-01.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m r_parse \u001b[39m=\u001b[39m BeautifulSoup(r\u001b[39m.\u001b[39mtext, \u001b[39m'\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/johan/Documents/Git/P6Opgaver/WebIntelligence/selfstudy-E22-01.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(r_parse\u001b[39m.\u001b[39mprettify())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r' is not defined"
     ]
    }
   ],
   "source": [
    "r_parse = BeautifulSoup(r.text, 'html.parser')\n",
    "print(r_parse.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'r_parse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\johan\\Documents\\Git\\P6Opgaver\\WebIntelligence\\selfstudy-E22-01.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/johan/Documents/Git/P6Opgaver/WebIntelligence/selfstudy-E22-01.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(r_parse\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/johan/Documents/Git/P6Opgaver/WebIntelligence/selfstudy-E22-01.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(r_parse\u001b[39m.\u001b[39mfind(\u001b[39m'\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mstring)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'r_parse' is not defined"
     ]
    }
   ],
   "source": [
    "print(r_parse.find('title'))\n",
    "print(r_parse.find('title').string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, we can get all the links on the page. The following also illustrates the sleep() function to implement time delays (the following will take a while to complete; use the \"interrupt kernel\" button to terminate early):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in r_parse.find_all('a'):\n",
    "    sleep(1)\n",
    "    print(a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParseResult(scheme='https', netloc='www.aau.dk', path='/uddannelser/optagelse/kandidat/ledige-studiepladser-2022', params='', query='', fragment='')\n",
      "https://www.aau.dk\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.aau.dk/uddannelser/optagelse/kandidat/ledige-studiepladser-2022'\n",
    "parsed = urlparse(url)\n",
    "print(parsed)\n",
    "newurl = parsed.scheme + '://' + parsed.netloc\n",
    "print(newurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.aau.dk\n",
      "AAU - Viden for verden - Aalborg Universitet\n",
      "1\n",
      "https://www.dr.dk\n",
      "DR | Nyheder - Breaking - TV - Radio\n",
      "2\n",
      "https://www.tv2.dk\n",
      "TV 2 - bedst pÃ¥ breaking og live\n",
      "3\n",
      "https://www.bt.dk\n",
      "B.T. Nyheder | Læs nyhederne på bt.dk\n",
      "4\n",
      "https://www.aau.dk/om-cookies\n",
      "Aalborg Universitets privatlivspolitik og cookiepolitik - Aalborg Universitet\n",
      "5\n",
      "https://www.okonomi.aau.dk\n",
      "Økonomiafdelingen\n",
      "6\n",
      "https://www.kvalitetssikring.aau.dk\n",
      "Uddannelseskvalitet på Aalborg Universitet\n",
      "7\n",
      "https://www.intern.aau.dk/\n",
      "Ansatte og studerende på AAU\n",
      "8\n",
      "https://www.berlingskemedia.dk/ophavsret-og-vilkaar/\n",
      "Ophavsret og vilkår\n",
      "9\n",
      "https://www.studerende.aau.dk\n",
      "For studerende på Aalborg Universitet - Aalborg Universitet\n",
      "10\n",
      "https://www.alumni.aau.dk/\n",
      "Alumni - Aalborg Universitet\n",
      "11\n",
      "https://www.was.digst.dk/aau-dk\n",
      "Tilgængelighedserklæring\n",
      "12\n",
      "https://www.linkedin.com/company/aalborg-university\n",
      "no title\n",
      "12\n",
      "https://www.instagram.com/aaustudieliv/\n",
      "Aalborg Universitet (@aaustudieliv) • Instagram photos and videos\n",
      "13\n",
      "https://www.en.aau.dk/alumni\n",
      "AAU Alumni - THE GATEWAY TO NETWORKING\n",
      "14\n",
      "https://www.berlingske.dk/\n",
      "Berlingske | Læs nyheder på berlingske.dk\n",
      "15\n",
      "https://www.students.aau.dk\n",
      "students\n",
      "16\n",
      "https://www.studiestart.aau.dk\n",
      "Studiestart\n",
      "17\n",
      "https://www.pressenaevnet.dk/\n",
      "www.pressenaevnet.dk | 520: Web server is returning an unknown error\n",
      "18\n",
      "https://www.dr.dk/om-dr/vilkaar-paa-drdk\n",
      "Vilkår på dr.dk | Om DR | DR\n",
      "19\n",
      "https://www.aub.aau.dk\n",
      "Aalborg Universitetsbibliotek\n",
      "20\n",
      "https://www.vacancies.aau.dk/\n",
      "Vacant positions at Aalborg University\n",
      "21\n",
      "https://www.design.aau.dk/\n",
      "AAU Designguide\n",
      "22\n",
      "https://www.en.okonomi.aau.dk\n",
      "finance and accounts department\n",
      "23\n",
      "https://www.aalborgbibliotekerne.dk/in-english/\n",
      "Siden blev ikke fundet | Aalborg Bibliotekerne\n",
      "24\n",
      "https://www.weekendavisen.dk/mine-sider/kundeservice\n",
      "Mine sider | Weekendavisen\n",
      "25\n",
      "https://www.colourbox.dk/\n",
      "Køb royalty-free billeder, videoer og vektorer | Colourbox\n",
      "26\n",
      "https://www.dr.dk/service/drs-persondatapolitik/\n",
      "DR’s privatlivspolitik | DR og dine data | DR\n",
      "27\n",
      "https://www.en.match.aau.dk/\n",
      "InfoGlue Error\n",
      "28\n",
      "https://www.en.aau.dk/education/student-guidance/news\n",
      "News\n",
      "29\n",
      "https://www.weekendavisen.dk/\n",
      "Weekendavisen | Weekendavisen\n",
      "30\n",
      "https://www.election.aau.dk/\n",
      "Election at Aalborg University\n",
      "31\n",
      "https://www.en.aau.dk/cooperation\n",
      "Cooperation with Aalborg University\n",
      "32\n",
      "https://www.twitter.com/share?url=undefined&text=DR%E2%80%99s%20privatlivspolitik\n",
      "no title\n",
      "32\n",
      "https://www.en.campusservice.aau.dk/aaucard\n",
      "Welcome to AAUCard\n",
      "33\n",
      "https://www.stillinger.aau.dk/\n",
      "Ledige stillinger på Aalborg Universitet\n",
      "34\n",
      "https://www.okonomi.aau.dk/organisation\n",
      "Områder i Økonomiafdelingen\n",
      "35\n",
      "https://www.campusservice.aau.dk/servicekontorer/\n",
      "Facility Support teams\n",
      "36\n",
      "https://www.adgangforalle.dk/\n",
      "Adgang for alle, online oplÃ¦sning \n",
      "37\n",
      "https://www.skyfish.com/\n",
      "Organize & share your company's images online | Skyfish\n",
      "38\n",
      "https://www.en.ekstranet.its.aau.dk/software/\n",
      "AAU - Login\n",
      "39\n",
      "https://www.its.aau.dk/\n",
      "AAU It services - Aalborg Universitet\n",
      "40\n",
      "https://www.en.search.aau.dk/?locale=en\n",
      "AAU Search - Aalborg University\n",
      "41\n",
      "https://www.aub.aau.dk/virksomheder-private/alumni\n",
      "Alumni biblioteksbrugere\n",
      "42\n",
      "https://www.sikkerhed.aau.dk/\n",
      "sikkerhed på AAU\n",
      "43\n",
      "https://www.update.aau.dk/intranet-medarbejderportaler/\n",
      "Intranet og medarbejderportaler\n",
      "44\n",
      "https://www.adgangforalle.dk/default.efact?pid=7953\n",
      "Support ved installation eller brug af porgrammet adgang for alle \n",
      "45\n",
      "https://www.careers.aau.dk/\n",
      "AAU Career\n",
      "46\n",
      "https://www.okonomi.aau.dk/\n",
      "Økonomiafdelingen\n",
      "47\n",
      "https://www.nyadgangskode.aau.dk\n",
      "Ny adgangskode på AAU\n",
      "48\n",
      "https://www.euroinvestor.dk/kundeservice\n",
      "no title\n",
      "48\n",
      "https://www.update.aau.dk/nyheder/\n",
      "Alle nyheder fra Update\n",
      "49\n",
      "https://www.aau.dk/samarbejde\n",
      "Samarbejde med Aalborg Universitet - Aalborg Universitet\n",
      "50\n",
      "https://www.intra.inside.aau.dk/kvalitet/Opgaver+i+kvalitetsarbejdet\n",
      "AAU - Login\n",
      "51\n",
      "https://www.intranet.its.aau.dk/\n",
      "AAU - Login\n",
      "52\n",
      "https://www.adgangforalle.dk/default.efact?pid=7946\n",
      "LÃ¦s om bagrunden for adgang for alle \n",
      "53\n",
      "https://www.youtube.com/channel/UCuhk7an3TQ7JtGKvrFW3neg\n",
      "Inden du fortsætter til YouTube\n",
      "54\n",
      "https://www.adgangforalle.dk/default.efact?pid=7954\n",
      "www.adgangforalle.dk \n",
      "55\n",
      "https://www.kvalitet.aau.dk/Kvalitetsdokumenter/\n",
      "Kvalitetssystemets dokumenter\n",
      "56\n",
      "https://www.studiestart.aau.dk/film-om-studielivet-paa-aau\n",
      "Film om studielivet på AAU\n",
      "57\n",
      "https://www.aauvalg.aau.dk/\n",
      "Valg på Aalborg Universitet\n",
      "58\n",
      "https://www.en.campusservice.aau.dk/facility-support-teams\n",
      "Facility support teams\n",
      "59\n",
      "https://www.en.aub.aau.dk/\n",
      "The University Library\n",
      "60\n",
      "https://www.canteen.aau.dk/koebenhavn/\n",
      "Copenhagen\n",
      "61\n",
      "https://www.intranet.kultur.aau.dk/\n",
      "AAU - Login\n",
      "62\n",
      "https://www.intranet.campusservice.aau.dk/\n",
      "AAU - Login\n",
      "63\n",
      "https://www.adm.aau.dk/vue/\n",
      "AAU - Login\n",
      "64\n",
      "https://www.canteen.aau.dk/esbjerg/\n",
      "esbjerg\n",
      "65\n",
      "https://www.intern.aau.dk/gdpr/\n",
      "Velkommen til persondata.aau.dk\n",
      "66\n",
      "https://www.intranet.okonomi.aau.dk/\n",
      "AAU - Login\n",
      "67\n",
      "https://www.intranet.politik-samfund.aau.dk/\n",
      "AAU - Login\n",
      "68\n",
      "https://www.en.search.aau.dk/?site=www.en.search.aau.dk&locale=en&mobile=false\n",
      "AAU Search - Aalborg University\n",
      "69\n",
      "https://www.handbook.aau.dk/document?contentId=365956\n",
      "AAU handbook\n",
      "70\n",
      "https://www.engineering.aau.dk/\n",
      "Det Ingeniør- og Naturvidenskabelige Fakultet - Aalborg Universitet\n",
      "71\n",
      "https://www.snapchat.com/add/aauuni\n",
      "Aalborg Universitet (@aauuni) on Snapchat\n",
      "72\n",
      "https://www.youtube.com/aalborguniversitet\n",
      "Inden du fortsætter til YouTube\n",
      "73\n",
      "https://www.datatilsynet.dk\n",
      "\n",
      "Datatilsynet\n",
      "\n",
      "74\n",
      "https://www.security.aau.dk/\n",
      "Security on AAU\n",
      "75\n",
      "https://www.stads.aau.dk/students/\n",
      "STADS self-service\n",
      "76\n",
      "https://www.sundhedsvidenskab.aau.dk/\n",
      "Det Sundhedsvidenskabelige Fakultet - Aalborg Universitet\n",
      "77\n",
      "https://www.bibliotek.dk\n",
      "bibliotek.dk | bibliotek.dk\n",
      "78\n",
      "https://www.euroinvestor.dk/\n",
      "Euroinvestor\n",
      "79\n",
      "https://www.intranet.business.aau.dk/\n",
      "AAU - Login\n",
      "80\n",
      "https://www.instagram.com/weekendavisen.dk/\n",
      "Weekendavisen (@weekendavisen.dk) • Instagram photos and videos\n",
      "81\n",
      "https://www.sea.aau.dk/\n",
      "AAU Student Entrepreneurship\n",
      "82\n",
      "https://www.its.aau.dk/vejledninger/infoglue/webdesign-og-seo/om-infoglue\n",
      "AAU - Login\n",
      "83\n",
      "https://www.intranet.soc.aau.dk/\n",
      "AAU - Login\n",
      "84\n",
      "https://www.bt.dk/mine-sider/kundeservice\n",
      "BT | Mine sider\n",
      "85\n",
      "https://www.intranet.mp.aau.dk/\n",
      "AAU - Login\n",
      "86\n",
      "https://www.staff.aau.dk/\n",
      "For staff at AAU\n",
      "87\n",
      "https://www.haandbog.aau.dk/dokument?contentId=365956\n",
      "AAU håndbogen\n",
      "88\n",
      "https://www.phd.engineering.aau.dk/\n",
      "The Doctoral School of Engineering and Science\n",
      "89\n",
      "https://www.en.update.aau.dk/\n",
      "AAU update\n",
      "90\n",
      "https://www.hst.aau.dk/\n",
      "Department of Health Science and Technology  - Aalborg University\n",
      "91\n",
      "https://www.studiepraktik.aau.dk\n",
      "Studiepraktik på AAU  - Aalborg Universitet\n",
      "92\n",
      "https://www.nyheder.aau.dk/2022/nyhed/femte-aar-i-traek--aau-er-europas-bedste-ingenioeruniversitet.cid524468\n",
      "Siden blev ikke fundet (404)\n",
      "93\n",
      "https://www.aauvalg.aau.dk/spoerg\n",
      "Spørg os\n",
      "94\n",
      "https://www.nyheder.aau.dk/\n",
      "AAU Nyhedsarkiv\n",
      "95\n",
      "https://www.aub.aau.dk/software-web/refworks/\n",
      "RefWorks\n",
      "96\n",
      "https://www.intranet.cs.aau.dk/\n",
      "AAU - Login\n",
      "97\n",
      "https://www.phd.engineering.aau.dk/Summer+School+2022/\n",
      "1st International Summer School at the Doctoral School of Engineering and Science – Aalborg University.\n",
      "98\n",
      "https://www.handbook.aau.dk/document\n",
      "AAU handbook\n",
      "99\n",
      "https://www.intranet.bio.aau.dk/\n",
      "AAU - Login\n",
      "100\n",
      "https://www.en.its.aau.dk/\n",
      "AAU It Services\n",
      "hello\n"
     ]
    }
   ],
   "source": [
    "seeds = ['https://www.aau.dk', 'https://www.dr.dk', 'https://www.tv2.dk', 'https://www.bt.dk', 'https://www.mit.edu']\n",
    "index_arr = []\n",
    "crawled_links = []\n",
    "frontier = []\n",
    "frontqueue = {\n",
    "    'one' : [],\n",
    "    'two' : [],\n",
    "    'three' : []\n",
    "}\n",
    "\n",
    "back_queue = {}\n",
    "prio_heap = {}\n",
    "\n",
    "for url in seeds :\n",
    "    prio_heap[url] = datetime.now()\n",
    "    back_queue[url] = []\n",
    "sleep(2)\n",
    "\n",
    "def get_base_url(url):\n",
    "    parsed = urlparse(url)\n",
    "    baseUrl = parsed.scheme + '://' + parsed.netloc\n",
    "    return baseUrl\n",
    "def fill_back_queue():\n",
    "    arr = []\n",
    "    if(len(frontqueue['one']) != 0):\n",
    "        arr = frontqueue['one']\n",
    "        frontqueue['one'] = []\n",
    "    elif(len(frontqueue['two']) != 0):\n",
    "        arr = frontqueue['two']\n",
    "        frontqueue['two'] = []\n",
    "    elif(len(frontqueue['three']) != 0):\n",
    "        arr = frontqueue['three']\n",
    "        frontqueue['three'] = []\n",
    "\n",
    "    for url in arr:\n",
    "        if (get_base_url(url) in back_queue.keys()):\n",
    "            back_queue[get_base_url(url)].append(url)\n",
    "            prio_heap[get_base_url(url)] = datetime.now()\n",
    "        else:\n",
    "            back_queue[get_base_url(url)] = [url]\n",
    "            prio_heap[get_base_url(url)] = datetime.now()\n",
    "\n",
    "def get_url():\n",
    "    #This should be based on a heap but :shrugeg:\n",
    "    viable_urls = [key for (key, value) in prio_heap.items() if value <= datetime.now() + timedelta(seconds=2)]\n",
    "\n",
    "    randomUrl = random.choice(viable_urls)\n",
    "    url = \"\"\n",
    "    if(len(back_queue[randomUrl]) != 0):\n",
    "        url = back_queue[randomUrl].pop()\n",
    "    else:\n",
    "        fill_back_queue()\n",
    "        return get_url()\n",
    "    crawled_links.append(randomUrl)\n",
    "    return url\n",
    "\n",
    "def fetch(url):\n",
    "    rp.set_url(get_base_url(url))\n",
    "    rp.read()\n",
    "    if (True):#rp.can_fetch(\"*\", url)):\n",
    "        r=requests.get(url)\n",
    "        r_parse = BeautifulSoup(r.text, 'html.parser')\n",
    "        return r_parse\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def index(doc):\n",
    "    title = doc.find('title')\n",
    "    if(title):\n",
    "        print(title.string)\n",
    "        index_arr.append(title.string)\n",
    "    else:\n",
    "        print('no title')\n",
    "\n",
    "def extract_urls(doc, url):\n",
    "    href_arr = [] \n",
    "    for a in doc.find_all('a', href=True):\n",
    "        link = a['href']\n",
    "        if(link.startswith('https://www')):\n",
    "            if (link not in frontier and link not in href_arr and link not in crawled_links):\n",
    "                href_arr.append(link)\n",
    "        #else:\n",
    "        #    comb_url = get_base_url(url) + link\n",
    "        #    if (comb_url not in frontier and comb_url not in href_arr and comb_url not in crawled_links):\n",
    "        #        href_arr.append(comb_url)\n",
    "    return href_arr\n",
    "\n",
    "def add_to_frontier(url_list):\n",
    "    #To make some checks easier this is added\n",
    "    for url in url_list:\n",
    "        frontier.append(url)\n",
    "        slash_count = url.count('/')\n",
    "        if (slash_count > 5):\n",
    "            frontqueue['three'].append(url)\n",
    "        elif(slash_count > 3):  \n",
    "            frontqueue['two'].append(url)\n",
    "        else:\n",
    "            frontqueue['one'].append(url)\n",
    "\n",
    "add_to_frontier(seeds)\n",
    "\n",
    "\n",
    "while (len(back_queue) != 0):\n",
    "    url = get_url()\n",
    "    print(url)\n",
    "    doc = fetch(url)\n",
    "    if (doc):\n",
    "        index(doc)\n",
    "        add_to_frontier(extract_urls(doc, url))\n",
    "    if(len(index_arr) > 100):\n",
    "        break\n",
    "    print(len(index_arr))\n",
    "print(\"hello\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "7198368533b4a9f7ada4a6f02ecfc216821b7313dc2a47d81fa173ab3879fbc0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
